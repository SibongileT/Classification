{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "\n",
    "client_id = 'b69091a51565464da8e8f5315482bfcd'\n",
    "client_secret = 'ff3e70920cdf42d1bb135adba578aa74'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager) #spotify object to access API\n",
    "\n",
    "def get_track_ID(artist,track_name):\n",
    "    searchResults = sp.search(q='artist:{} track:{}'.format(artist, track_name),limit=1)\n",
    "    spotifyId =  searchResults['tracks']['items'][0]['id']\n",
    "    return spotifyId\n",
    "\n",
    "def get_track_features(id):\n",
    "    \n",
    "    meta = sp.track(id)\n",
    "    features = sp.audio_features(id)\n",
    "    analysis = sp.audio_analysis(id)\n",
    "    # meta\n",
    "    name = meta['name']\n",
    "    artist = meta['album']['artists'][0]['name']\n",
    "    duration_ms = meta['duration_ms']\n",
    "\n",
    "    # features\n",
    "    acousticness = features[0]['acousticness']\n",
    "    danceability = features[0]['danceability']\n",
    "    energy = features[0]['energy']\n",
    "    instrumentalness = features[0]['instrumentalness']\n",
    "    liveness = features[0]['liveness']\n",
    "    loudness = features[0]['loudness']\n",
    "    speechiness = features[0]['speechiness']\n",
    "    tempo = features[0]['tempo']\n",
    "    time_signature = features[0]['time_signature']\n",
    "    key = features[0]['key']\n",
    "    mode = features[0]['mode']\n",
    "    valence = features[0]['valence']\n",
    "    \n",
    "    #audio anaylsis\n",
    "    chorus_hit = analysis['sections'][0]['duration']*2\n",
    "    sections = len(analysis['sections'])\n",
    "    \n",
    "    track = [name , artist, danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,liveness,valence,tempo,duration_ms,time_signature,\\\n",
    "    chorus_hit,sections]\n",
    "    return track\n",
    "\n",
    "def get_track_audio(track_id):\n",
    "    song_uri = 'spotify:track:{}'.format(track_id)\n",
    "\n",
    "    track = sp.track(song_uri)\n",
    "    name = track['name']\n",
    "    audio_preview = track['preview_url']\n",
    "    cover_art = track['album']['images'][0]['url']\n",
    "    return name,audio_preview,cover_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = get_track_ID('SNo','Red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features = get_track_features(track_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red',\n",
       " 'Taylor Swift',\n",
       " 0.602,\n",
       " 0.896,\n",
       " 1,\n",
       " -4.267,\n",
       " 0,\n",
       " 0.0437,\n",
       " 0.0773,\n",
       " 8.87e-05,\n",
       " 0.091,\n",
       " 0.641,\n",
       " 124.978,\n",
       " 220826,\n",
       " 4,\n",
       " 15.79398,\n",
       " 11]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(track_features):\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    artist_df = pd.read_csv(\"artist_df.csv\")\n",
    "    filename = 'finalized_model.sav'\n",
    "    PREDICT = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "    scaledfile = 'finalized_scale.sav'\n",
    "    scaler = pickle.load(open(scaledfile, 'rb'))\n",
    "    zeroes = np.zeros(80)\n",
    "    \n",
    "    x = [track_features[2:]]\n",
    "  \n",
    "    x = get_encoded_artist(track_features[1],artist_df,x)\n",
    "    print(len(x[0]))\n",
    "    x_scaled = scaler.transform(x)\n",
    "    result = PREDICT.predict(x_scaled)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_artist(artist,df,x):\n",
    "    for col in df.columns:\n",
    "        if col == artist:\n",
    "            x[0].append(1)\n",
    "        else:\n",
    "            x[0].append(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "get_predictions(track_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
